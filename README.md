# Tangma

## Overview

This project implements Tangma, an activation function combining tunable nonlinearity and residual linearity for deep learning models. It helps training performance by preventing issues like vanishing gradients, while softening high intensity activations. 

## Project Structure

```plaintext
Tangma/
├── cifar10_cnn.ipynb                    # full implmentation (defining activation functions + custom CIFAR10 CNN)
├── mnist_cnn.ipynb                   # same as above but MNIST CNN

